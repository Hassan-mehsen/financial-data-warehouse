
x-airflow-common: 
  &airflow-common

  build:
    context: .
    dockerfile: airflow/Dockerfile

  environment:
    &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${DB_URL}
    AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    
    AIRFLOW__CORE__AUTH_MANAGER: "airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager"
    AIRFLOW__CORE__FERNET_KEY: ''
    
    AIRFLOW__CORE__EXECUTION_API_SERVER_URL: 'http://localhost:8080/execution/'
    AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'

    AIRFLOW_HOME: "/opt/airflow"
    AIRFLOW__CORE__DAGS_FOLDER: "/opt/airflow/dags"

    # EL jobs variabels 
    FMP_API_KEY: ${FMP_API_KEY}
    DATABASE_URL: ${DATABASE_URL}

  volumes:
    # In prod, delete dags and src volumes
    - ./airflow/dags:/opt/airflow/dags
    - ./src:/opt/airflow/src
    - /var/run/docker.sock:/var/run/docker.sock

    # Persist logs to host (bind)
    - ./airflow/logs:/opt/airflow/logs
    - ./el_logs:/opt/airflow/el_logs

  user: airflow

  depends_on:
    postgres:
      condition: service_healthy


services:
  postgres:
    image: postgres:15
    container_name: airflow_postgres
    environment:
      POSTGRES_USER: ${DATABASE_USER}
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
      POSTGRES_DB: ${AIRFLOW_DB}
    ports:
      - "5000:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${DATABASE_USER}"]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: always
    

  airflow-init:
    <<: *airflow-common
    container_name: airflow_finance_init
    command : version
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_MIGRATE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD}


  airflow-all-services:
    <<: *airflow-common
    container_name: airflow_finance
    ports:
     - "8080:8080"
    environment:
      <<: *airflow-common-env
      DBT_PROFILES_DIR: ${DBT_PROFILES_DIR}
      DBT_DB_PORT:      ${DBT_DB_PORT}
      DBT_DB_HOST:      ${DBT_DB_HOST}
      DBT_DB_USER:      ${DBT_DB_USER}
      DBT_DB_PASSWORD:  ${DBT_DB_PASSWORD}
      DBT_DB_NAME:      ${DBT_DB_NAME}
      DBT_DB_SCHEMA:    ${DBT_DB_SCHEMA}
      
    # Allow container to reach local postgres 
    extra_hosts:
      - "host.docker.internal:host-gateway"
  
    command: >
      bash -c "
        airflow db migrate &&
        airflow scheduler &
        airflow api-server
      "
    

  dbt:
      build: ./dbt_financial_market
      image: dbt_finance
      container_name: dbt
      volumes:
        # Persist logs on host
        - ./dbt_financial_market/logs/:/usr/app/logs
      environment:
          DBT_PROFILES_DIR: ${DBT_PROFILES_DIR}
          DBT_DB_PORT:      ${DBT_DB_PORT}
          DBT_DB_HOST:      ${DBT_DB_HOST}
          DBT_DB_USER:      ${DBT_DB_USER}
          DBT_DB_PASSWORD:  ${DBT_DB_PASSWORD}
          DBT_DB_NAME:      ${DBT_DB_NAME}
          DBT_DB_SCHEMA:    ${DBT_DB_SCHEMA}
      extra_hosts:
        - "host.docker.internal:host-gateway"

      command: ["sleep","1000000"]


  metabase:
    image: metabase/metabase:latest
    container_name: metabase_finance
    ports:
      - "3000:3000"
    environment:
      MB_DB_TYPE: ${MB_DB_TYPE}
      MB_DB_DBNAME: ${MB_DB_NAME}
      MB_DB_PORT: ${MB_DB_PORT}
      MB_DB_USER: ${MB_DB_USER}
      MB_DB_PASS: ${MB_DB_PASSWORD}
      MB_DB_HOST: ${MB_DB_HOST}
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      postgres:
        condition: service_healthy
    restart: always
 
volumes:
  postgres_data:
